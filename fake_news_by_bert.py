# -*- coding: utf-8 -*-
"""fake news by bert.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R4wxq0n7yH2iAn_kcxoHCRbfXeYS_u7p
"""

import pandas as pd
import torch
from torch.utils.data import TensorDataset, DataLoader
from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_scheduler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Load combined dataset
dataset = pd.read_csv('/content/combined_news_dataset.csv')

# Initialize BERT tokenizer
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

# Tokenize dataset
def tokenize_data(texts, tokenizer, max_length):
    tokenized_texts = tokenizer(
        texts.tolist(),
        max_length=max_length,
        padding='max_length',
        truncation=True,
        return_tensors='pt'
    )
    return tokenized_texts

max_length = 128
tokenized_dataset = tokenize_data(dataset['title'], tokenizer, max_length)

# Convert tokenized dataset to PyTorch tensors
input_ids = tokenized_dataset['input_ids']
attention_mask = tokenized_dataset['attention_mask']
labels = torch.tensor(dataset['label'].tolist())

# Create TensorDataset and DataLoader
dataset = TensorDataset(input_ids, attention_mask, labels)
batch_size = 16
dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

# Load pre-trained BERT model for sequence classification
model = BertForSequenceClassification.from_pretrained(
    'bert-base-uncased',
    num_labels=2,  # Binary classification (fake vs real)
    output_attentions=False,
    output_hidden_states=False,
)

# Define optimizer and scheduler
optimizer = AdamW(model.parameters(), lr=2e-5)
num_epochs = 3
num_training_steps = num_epochs * len(dataloader)
scheduler = get_scheduler(
    "linear",
    optimizer=optimizer,
    num_warmup_steps=0,
    num_training_steps=num_training_steps
)

# Training loop
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
model.train()


for epoch in range(num_epochs):
    for batch in dataloader:
        optimizer.zero_grad()
        batch = tuple(t.to(device) for t in batch)
        inputs = {'input_ids': batch[0],
                  'attention_mask': batch[1],
                  'labels': batch[2]}

        outputs = model(**inputs)
        loss = outputs.loss
        loss.backward()
        optimizer.step()
        scheduler.step()

# Evaluation
model.eval()
eval_dataloader = DataLoader(dataset, batch_size=batch_size)
preds = []
true_labels = []

for batch in eval_dataloader:
    batch = tuple(t.to(device) for t in batch)
    with torch.no_grad():
        inputs = {'input_ids': batch[0],
                  'attention_mask': batch[1]}
        outputs = model(**inputs)
        logits = outputs.logits
        preds.extend(logits.argmax(dim=-1).cpu().numpy())
        true_labels.extend(batch[2].cpu().numpy())

# Calculate evaluation metrics
accuracy = accuracy_score(true_labels, preds)
precision = precision_score(true_labels, preds)
recall = recall_score(true_labels, preds)
f1 = f1_score(true_labels, preds)

print(f'Accuracy: {accuracy}')
print(f'Precision: {precision}')
print(f'Recall: {recall}')
print(f'F1 Score: {f1}')

import os as os

# Save the model and tokenizer
model_dir = './saved_model'
if not os.path.exists(model_dir):
    os.makedirs(model_dir)
model.save_pretrained(model_dir)
tokenizer.save_pretrained(model_dir)

# Function to test the model with new text input
def test_model(input_text, model, tokenizer, max_length):
    model.eval()
    inputs = tokenizer(input_text, return_tensors='pt', max_length=max_length, padding='max_length', truncation=True)
    inputs = {key: value.to(device) for key, value in inputs.items()}
    with torch.no_grad():
        outputs = model(**inputs)
        prediction = torch.argmax(outputs.logits, dim=-1).item()
    return 'Fake News' if prediction == 1 else 'Real News'

# Example usage:
new_text = "tomorrow world will fall agents the china"
prediction = test_model(new_text, model, tokenizer, max_length)
print(f'Prediction for "{new_text}": {prediction}')